write x/storm

Write an application that allows a more dynamic, asynchronous, rapid
interaction with one or more LLMs, similar to the ChatGPT or
Perplexity UI, but with faster, more granular, continuous interaction
rather than the slower, synchronous behavior of existing LLM chat UIs.
The application should:

- start an HTTP server listening on a port given on the command line
- return a web page that is similar to the UI of ChatGPT or Perplexity
- allow the user to select a LLM and enter a query
- append the query to the page, similar to a chat UI
- send the query to the LLM via the Grokker API, asking for markdown
  formatted text
- format the response from the LLM as HTML
- add javascript to the HTML page to allow the user to select
  any block of text and comment on it, similar to Google Doc comments
- return the HTML to the user's browser
- accept each individual comment as a separate query to the LLM
- append the comments to the page while the API query is running,
  allowing the user to continue commenting and scrolling as the
  replies come back from the LLMs and are added after their respective
  queries.
- maintain a text box at the bottom of the page for the user to
  enter new queries or comments on the same page
- use goldmark or similar to render the markdown response to HTML
- Do not scroll the page when new content is added at the bottom of
  the page.  The user MUST be able to continue reading and commenting
  on the existing content without interruption. The current code
  attempts to save the scroll position, but this does not work
  correctly when new content is added at the bottom of the page. Isn't
  there some browser API that allows the page to be dynamically
  updated without scrolling the page?  Make ONLY this change.  Do NOT
  make any additional changes to the code, the page layout, or the
  styling.  Do NOT delete or reformat any existing comments. Do NOT
  rewrap any existing lines. Do NOT change the HTML structure of the
  page.
- Add a progress spinner next to each outstanding query that has not
  yet been completed. The spinners should be added
  immediately after the user submits a query or comment, and they
  should be removed when the LLM response is received and displayed on
  the page.  
- Each query should be added to the bottom of the page as soon as it's
  entered, without waiting for the LLM response. There should be a
  progress spinner next to each query while the query is waiting for a
  response.  The spinner should be a simple 10px by 10px spinner, 
  similar to the one used in the existing code.  The spinner should
  go away when the LLM response is received, to be replaced by the
  response text.  

New requirements:

- Add a status box to the bottom right corner of the page, to the
  right of the "Send" button. The status box should display the
  "Token Count:" label and the number of tokens in the current
  conversation. The token count should be updated dynamically as the
  conversation progresses. The token count should be calculated
  using the `TokenCount` function in the `Grokker` struct. The
  signature of the `TokenCount` function is as follows:

```go
func (g *Grokker) TokenCount(text string) (count int, err error) 
```

In:
  x/storm/main.go
Out:
  x/storm/main.go


.stop

.stop

each agent uses LLM to compose messages

Modify main.go and main_test.go to implement the following
requirements:

Before an agent sends a message, it MUST compose the message by
sending its goal.md, pseudocode.md, and messages.log files to the
Grokker API at the given model using the SendWithFiles function. The
Grokker API will then generate a message based on the agent's current
state and the communication protocols it has learned, and the agent
MUST extract the message from the API response using the ExtractFiles
function. The agent will then send this message to the intended
recipient via the main goroutine.

The agent subdirectory MUST also contain a sysmsg.md file that contains
the system message that the agent will use to generate its messages.
The content of this file MUST be used to set the system message for
the Grokker API. See example-agent-sysmsg.md for an example of an
sysmsg.md file.

If you are unable to meet these requirements, please add a comment in the
code explaining why you cannot meet the requirements and what you
need from me to help you meet the requirements.

Other requirements are in requirements.md.

Sysmsg:                                                                                                                     
  You are an expert software developer specialized in creating
  adaptive, multi-agent systems simulations using the Go programming
  language. Your task is to generate modular and scalable Go code to
  simulate a system of agents communicating with each other. The
  agents must dynamically evolve their communication protocols over
  time based on the tasks they perform, rather than using pre-defined
  message formats. The agents should discover new communication
  strategies through interaction, and adapt their message structure to
  improve coordination and task efficiency. Ensure that the code
  leverages concurrency, is easily extendable for new agent types, and
  allows for flexible message parsing and generation. Do not
  quote or escape single backticks in Go code -- Go uses backticks
  for raw string literals.  Do not remove or alter comments unless
  they are incorrect or misleading.  Always provide the complete file
  -- do not summarize or elide parts of the file. Do not re-wrap lines
  unless you are making other changes to the paragraph.  Lines must be
  wrapped at 70 characters.  
In:
  x/adaptive-communication/requirements.md
  x/adaptive-communication/example-agent-sysmsg.md
  v3/cli/cli.go
  v3/aidda/aidda.go
  v3/core/chat.go
  x/adaptive-communication/main.go
  x/adaptive-communication/main_test.go
Out:
  x/adaptive-communication/main.go
  x/adaptive-communication/main_test.go

.stop


analyze the given code and make recommendations for improvements

In:
    v3/util/util.go
    v3/cli/chat_test.go
    v3/cli/cli.go
    v3/cli/cli_test.go
    v3/cli/migration_test.go
    v3/lang/go/split.go
    v3/lang/go/split_test.go
    v3/core/grokker_test.go
    v3/core/chunk.go
    v3/core/chat.go
    v3/core/migrate.go
    v3/core/grokker.go
    v3/core/gateway.go
    v3/core/git.go
    v3/core/model.go
    v3/core/api.go
    v3/core/document.go
    v3/cmd/grok/main.go
    v3/aidda/aidda_test.go
    v3/aidda/cmd/aidda3/main.go
    v3/aidda/run.go
    v3/aidda/aidda.go
    x/perplexity-example.go
    v3/client/chatclient.go
    v3/openai/openai.go
    v3/perplexity/perplexity.go

.stop

ensure aidda-generated code is committed before prompt file is edited again

Brainstorm how I might ensure that the aidda-generated code is
committed before the prompt file is edited again.  I keep forgetting
to hit '[c]ommit' after '[g]enerate' and then I edit the prompt file
again and the prompt file that should have been used as the commit
message is no longer available without hitting undo a bunch of times
in the editor.

Understand that I keep the editor (neovim) open and run the aidda
command in a temporary neovim terminal window.  I don't set the
AIDDA_EDITOR environment variable to open the editor because I want to
keep the editor open between aidda runs.  I don't see or run the aidda
menu otherwise, so I can't see any warning or disabled menu selections in
the aidda menu until after I've erroneously edited the prompt file
and run the aidda menu command again.

Also understand that other users might be using a different editor or
might not be using a terminal-based editor at all, so I can't rely on
neovim-specific features to solve this problem.

In your brainstorming, consider these solutions but add your own ideas
as well:

- set the prompt file to read-only after generating code, then read-write
  after committing
- transform the role of the prompt file to be instead a menu itself;
  get rid of the separate aidda menu, have aidda be a daemon that
  watches the prompt file for changes and runs the appropriate command
  when the prompt file is saved; have aidda modify the prompt file
  as needed to indicate the state of the aidda-generated code and
  commit status
In:
    v3/aidda/aidda.go

.stop

In: 
    .aidda/plan.md
    v3/util/util.go
    v3/cli/chat_test.go
    v3/cli/cli.go
    v3/cli/cli_test.go
    v3/cli/migration_test.go
    v3/lang/go/split.go
    v3/lang/go/split_test.go
    v3/core/grokker_test.go
    v3/core/chunk.go
    v3/core/chat.go
    v3/core/migrate.go
    v3/core/grokker.go
    v3/core/gateway.go
    v3/core/git.go
    v3/core/model.go
    v3/core/api.go
    v3/core/document.go
    v3/cmd/grok/main.go
    v3/aidda/aidda_test.go
    v3/aidda/cmd/aidda3/main.go
    v3/aidda/run.go
    v3/aidda/aidda.go
    x/perplexity-example.go
    v3/client/chatclient.go
    v3/openai/openai.go
    v3/perplexity/perplexity.go
    x/patterns.md
