package grokker

import (
	"os"
	"time"

	"github.com/fabiustech/openai"
	oai "github.com/sashabaranov/go-openai"
	. "github.com/stevegt/goadapt"
	"github.com/tiktoken-go/tokenizer"
)

// Grokker is a library for analyzing a set of documents and asking
// questions about them using the OpenAI chat and embeddings APIs.
//
// It uses this algorithm (generated by ChatGPT):
//
// To use embeddings in conjunction with the OpenAI Chat API to
// analyze a document, you can follow these general steps:
//
// (1) Break up the document into smaller text chunks or passages,
// each with a length of up to 8192 tokens (the maximum input size for
// the text-embedding-ada-002 model used by the Embeddings API).
//
// (2) For each text chunk, generate an embedding using the
// openai.Embedding.create() function. Store the embeddings for each
// chunk in a data structure such as a list or dictionary.
//
// (3) Use the Chat API to ask questions about the document. To do
// this, you can use the openai.Completion.create() function,
// providing the text of the previous conversation as the prompt
// parameter.
//
// (4) When a question is asked, use the embeddings of the document
// chunks to find the most relevant passages for the question. You can
// use a similarity measure such as cosine similarity to compare the
// embeddings of the question and each document chunk, and return the
// chunks with the highest similarity scores.
//
// (5) Provide the most relevant document chunks to the
// openai.Completion.create() function as additional context for
// generating a response. This will allow the model to better
// understand the context of the question and generate a more relevant
// response.
//
// Repeat steps 3-5 for each question asked, updating the conversation
// prompt as needed.

// Semantic Versioning
// https://semver.org/spec/v2.0.0.html
// MAJOR.MINOR.PATCH
// MAJOR version when you make incompatible API changes,
// MINOR version when you add functionality in a backwards compatible manner
//   - we're using this for db version migrations
//
// PATCH version when you make backwards compatible bug fixes.
//
// Any odd-numbered element indicates an unstable pre-release version
// that is collecting changes for the next stable release, and these
// changes may be pushed without a version number increase. Examples:
//   - 2.2.2 is a stable release version
//   - 2.2.3 is collecting code changes that will become 2.2.4
//   - 2.3.4 is collecting db and code changes that will become 2.4.0
//   - 3.2.2 is collecting API, db, and code changes that will become 4.0.0
const (
	version = "3.0.0"
)

type GrokkerInternal struct {
	embeddingClient *openai.Client
	chatClient      *oai.Client
	// The grokker version number this db was last updated with.
	Version string
	// The absolute path of the root directory of the document
	// repository.  This is passed in from cli based on where we
	// found the db.
	Root string
	// The list of documents in the database.
	Documents []*Document
	// The list of chunks in the database.
	Chunks []*Chunk
	// model specs
	models              *Models
	Model               string
	oaiModel            string
	tokenLimit          int
	embeddingTokenLimit int
	grokpath            string
	// lock                *flock.Flock
}

var Tokenizer tokenizer.Codec

// mtime returns the last modified time of the Grokker database.
func (g *GrokkerInternal) mtime() (timestamp time.Time, err error) {
	defer Return(&err)
	fi, err := os.Stat(g.grokpath)
	Ck(err)
	timestamp = fi.ModTime()
	return
}

// tokens returns the tokens for a text segment.
func (g *GrokkerInternal) tokens(text string) (tokens []string, err error) {
	defer Return(&err)
	_, tokens, err = Tokenizer.Encode(text)
	Ck(err)
	return
}
